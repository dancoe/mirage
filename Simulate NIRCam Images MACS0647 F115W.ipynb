{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate NIRCam Images\n",
    "\n",
    "## Using MIRAGE and the JWST Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/spacetelescope/mirage/blob/master/examples/Imaging_simulator_use_examples.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use MIRAGE to simulate NIRCam imaging based on HST observations of the galaxy cluster MACS0647+70.  \n",
    "Our full APT program executes 160 exposures = 4 dithers x 4 filters x 10 detectors.\n",
    "Here we simulate images in one filter in one NIRCam Module A.\n",
    "For the short wavelength filters, that will be 4 dithers x 4 detectors = 16 images.\n",
    "For the long wavelength filters,  that will be 4 dithers x 1 detector  =  4 images.\n",
    "\n",
    "Then we run the JWST pipeline to combine all 16 or 4 exposures into one image.\n",
    "\n",
    "Inputs:  \n",
    "APT file outputs: .xml, .pointing\n",
    "Galaxy catalog incl. RA, Dec, Sersic fit parameters, magnitude\n",
    "\n",
    "Outputs:  \n",
    "MIRAGE Simulated NIRCam FITS images (raw.fits; don't save linear.fits)\n",
    "JWST Pipeline Reduced NIRCam FITS images and catalog (id2.fits, cat.ecsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JWST Pipeline run including recommendations from CEERS program DR1\n",
    "\n",
    "Their notebook ceers_nircam_reduction.ipynb offers detailed help and instructions\n",
    "\n",
    "https://ceers.github.io/releases.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jwst-docs.stsci.edu/jwst-data-reduction-pipeline\n",
    "\n",
    "https://jwst-docs.stsci.edu/jwst-data-reduction-pipeline/algorithm-documentation/stages-of-processing\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/introduction.html\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image3.html\n",
    "\n",
    "\"In order to process and combine multiple images, an ASN file must be used as input, listing the exposures to be processed.\"\n",
    "    \n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/associations/asn_from_list.html\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/associations/level3_asn_technical.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/spacetelescope/nircam_calib/blob/master/nircam_calib/training_notebooks/jwst_pipeline_walkthrough.ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_uncal.fits (1b)  [_linear.fits not used here]\n",
    "Stage 1: Detector1Pipeline: Count-rate slopes: Detector-level corrections and ramp fitting\n",
    "_rate.fits (2a) -- cosmic rays removed\n",
    "Stage 2: Image2Pipeline: Calibrations: Instrument-mode\n",
    "_cal.fits (2b) -- galaxy wings appear after background subtraction and flat field correction\n",
    "Stage 3: Combining multiple exposures within an observation\n",
    "_id2.fits (2c) -- drizzled image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "STScI VPN required to acces files\n",
    "e.g., /grp/crds/cache/references/jwst/jwst_nircam_mask_0033.fits MASK reference file \n",
    "/grp/crds/cache/references/jwst/jwst_nircam_linearity_0053.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outstanding issues / room for improvement:\n",
    "\n",
    "- Darks\n",
    "- Stars too small\n",
    "- Align SW & LW images\n",
    "- CEERS improvements\n",
    "- Color images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_to_process = 'F115W'\n",
    "# Uncomment CEERS tweaks below next time you run this\n",
    "obs_to_process = ['010', '020']  # 2 NIRCam epochs\n",
    "module_to_process = 'A'\n",
    "exposures_to_process = 'all'  # [1]  # e.g., 1, 2, 3, 4 -OR- 'all' to process all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the xml and pointing files exported from APT\n",
    "APT_input_dir     = './inputs/'  # APT\n",
    "APT_file = os.path.join(APT_input_dir, 'macs0647_NIRCam')\n",
    "xml_file      = APT_file + '.xml'\n",
    "pointing_file = APT_file + '.pointing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source catalogs\n",
    "target = 'MACS0647+7015'  # must correspond to observed target in APT file!!\n",
    "# Otherwise may throw error when calculating catalog seed image\n",
    "cat_dict = {target:{}}\n",
    "galaxy_catalog_file = 'MACS0647_MIRAGE_galaxy_catalog_%s.cat' % filt_to_process\n",
    "cat_dict[target]['galaxy'] = galaxy_catalog_file\n",
    "#cat_dict[target]['point_source'] = 'imaging_example_data/ptsrc_catalog.cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reffile_defaults = 'crds'  # Reference file values: crds or crds_full_name\n",
    "cosmic_rays = {'library': 'SUNMAX', 'scale': 1.0}  # Cosmic ray library and rate\n",
    "background = 'medium'\n",
    "pav3 = 12.5  # telescope roll angle\n",
    "dates = '2022-10-31'  # won't be used by MIRAGE, but will be added to FITS headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir     = './yaml/'    # yaml files\n",
    "simulation_dir = './images/'  # simulated images\n",
    "output_dir = simulation_dir\n",
    "\n",
    "#yaml_dir  = './yaml/'    # yaml files\n",
    "image_dir = './images/'  # simulated images\n",
    "yaml_dir = image_dir\n",
    "\n",
    "#datatype = 'linear, raw'  # Save both raw (for JWST pipeline) and linear (processed except for dark current subtraction)\n",
    "datatype = 'raw'  # Save raw images only for JWST pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import MIRAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mirage\n",
    "os.environ[\"CRDS_DATA\"] = \"$HOME/crds_cache\"\n",
    "os.environ[\"CRDS_SERVER_URL\"] = \"https://jwst-crds.stsci.edu\"\n",
    "os.environ[\"MIRAGE_DATA\"] = \"/ifs/jwst/wit/mirage_data\"  # internal to STScI\n",
    "mirage.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:  # for users external to STScI\n",
    "    # Download 343 GB of files (will take some time!)\n",
    "    from mirage.reference_files import downloader\n",
    "    download_path = os.path.join(home, 'MIRAGE', 'data')\n",
    "    os.makedirs(download_path, exist_ok=True)\n",
    "    downloader.download_reffiles(download_path, instrument='nircam', dark_type='both',  # linearized\n",
    "                                 skip_darks=False, skip_cosmic_rays=False, skip_psfs=False, skip_grism=True)\n",
    "    \n",
    "    os.environ[\"MIRAGE_DATA\"] = download_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirage imports\n",
    "from mirage import imaging_simulator\n",
    "from mirage.seed_image import catalog_seed_image\n",
    "from mirage.dark import dark_prep\n",
    "from mirage.ramp_generator import obs_generator\n",
    "from mirage.yaml import yaml_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import JWST Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwst\n",
    "from jwst.pipeline import Detector1Pipeline, Image2Pipeline\n",
    "from jwst.associations.lib.rules_level2_base import DMSLevel2bBase\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from jwst.associations import asn_from_list\n",
    "from jwst.pipeline import calwebb_image3\n",
    "jwst.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the yaml generator (takes a minute or so)\n",
    "yam = yaml_generator.SimInput(input_xml=xml_file, pointing_file=pointing_file, catalogs=cat_dict, \n",
    "                              cosmic_rays=cosmic_rays, background=background, roll_angle=pav3, dates=dates, \n",
    "                              reffile_defaults=reffile_defaults, datatype=datatype, verbose=True,\n",
    "                              output_dir=yaml_dir, simdata_output_dir=image_dir)\n",
    "\n",
    "# https://mirage-data-simulator.readthedocs.io/en/latest/dark_preparation.html#calibration-and-linearization\n",
    "yam.use_linearized_darks = False\n",
    "\n",
    "yam.create_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yam.use_linearized_darks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 filters x 4 dithers x 10 detectors (as specified in APT)\n",
    "yfiles = glob(os.path.join(yaml_dir,'jw*.yaml'))\n",
    "yfiles = np.sort(yfiles)\n",
    "len(yfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print info about these files: filter and detector\n",
    "for yamlfile in yfiles:\n",
    "    with open(yamlfile, 'r') as infile:\n",
    "        params = yaml.safe_load(infile)\n",
    "    filt = params['Readout']['filter']\n",
    "    detector = params['Readout']['array_name'][3:5]\n",
    "    print(filt, detector, params['Output']['observation_number'], yamlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print info about these files: filter and detector\n",
    "for yamlfile in yfiles:\n",
    "    with open(yamlfile, 'r') as infile:\n",
    "        params = yaml.safe_load(infile)\n",
    "    filt = params['Readout']['filter']\n",
    "    detector = params['Readout']['array_name'][3:5]\n",
    "    if detector == 'A2':\n",
    "        break\n",
    "        \n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(params['Output']['exposure_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if   module_to_process == 'A':\n",
    "    yfiles = [yfile for yfile in yfiles if '_nrca' in yfile]  # Select only images in NIRCam Module A\n",
    "elif module_to_process == 'B':\n",
    "    yfiles = [yfile for yfile in yfiles if '_nrcb' in yfile]  # Select only images in NIRCam Module B\n",
    "\n",
    "#a5files = [yfile for yfile in yfiles if 'a5.' in yfile] # Select only Module A Long Wavelength images: detector A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exposures_to_process = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select filter observations\n",
    "yamls_to_process = []\n",
    "for yamlfile in yfiles:\n",
    "    with open(yamlfile, 'r') as infile:\n",
    "        params = yaml.safe_load(infile)\n",
    "    yaml_filt = params['Readout']['filter']\n",
    "    obs_num = params['Output']['observation_number']\n",
    "    if obs_num in obs_to_process:\n",
    "        if yaml_filt == filt_to_process:\n",
    "            if (exposures_to_process == 'all') or (int(params['Output']['exposure_number']) in exposures_to_process):\n",
    "                yamls_to_process.append(yamlfile)\n",
    "        \n",
    "len(yamls_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yamls_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only create images that haven't been created already\n",
    "yamls = np.sort(yamls_to_process)\n",
    "yamls_to_process = []\n",
    "for yamlfile in yamls:\n",
    "    outfits = yamlfile.replace('.yaml', '_uncal.fits')\n",
    "    already_did_it = os.path.exists(outfits)\n",
    "    havent_done_it_yet = not already_did_it\n",
    "    if havent_done_it_yet:\n",
    "        yamls_to_process.append(yamlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yamls_to_process) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yamls_to_process = np.sort(yamls_to_process)\n",
    "yamls_to_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the simulated images (will take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 minutes per image\n",
    "cal_images = []\n",
    "for yfile in yamls_to_process:\n",
    "    print(yfile)\n",
    "    uncal_image = yfile.replace('.yaml', '_uncal.fits').replace(yaml_dir, image_dir)\n",
    "    rate_image = uncal_image.replace('_uncal.fits', '_rate.fits')\n",
    "    cal_image  = uncal_image.replace('_uncal.fits', '_cal.fits')\n",
    "    cal_images.append(cal_image)\n",
    "\n",
    "    # MIRAGE\n",
    "    # 10 minutes per image\n",
    "    if not os.path.exists(uncal_image):\n",
    "        m = imaging_simulator.ImgSim()\n",
    "        m.paramfile = yfile\n",
    "        m.create()\n",
    "        \n",
    "    hdu = fits.open(uncal_image)\n",
    "    try:\n",
    "        noutputs = hdu[0].header['NOUTPUTS']\n",
    "    except:\n",
    "        hdu[0].header['NOUTPUTS'] = 4\n",
    "        hdu.writeto(uncal_image, overwrite=True)\n",
    "\n",
    "    # JWST Pipeline\n",
    "    # 20 minutes per image\n",
    "    if not os.path.exists(cal_image):\n",
    "        result1 = Detector1Pipeline()\n",
    "        result1.dark_current.skip = False\n",
    "        result1.jump.rejection_threshold = 21\n",
    "        result1.ipc.skip = False  # Correct for interpixel capicitance simulated by MIRAGE\n",
    "        result1.persistence.skip = True  # Persistence not simulated by MIRAGE\n",
    "        result1.save_results = True\n",
    "        result1.output_dir = image_dir\n",
    "        result1.run(uncal_image) # uncal -> rate\n",
    "        #\n",
    "        result2 = Image2Pipeline()\n",
    "        result2.resample.skip = True  # Don't produce individual id2 images (rectified quick-look)\n",
    "        result2.save_results = True\n",
    "        result2.output_dir = image_dir\n",
    "        result2.run(rate_image) # rate -> cal, id2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jw01433010001_01101_00012_nrca5_uncal.fits\n",
    "#glob('./images/*uncal.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine exposures into one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_images = []\n",
    "for yfile in yamls_to_process:\n",
    "    uncal_image = yfile.replace('.yaml', '_uncal.fits').replace(output_dir, simulation_dir)\n",
    "    rate_image = uncal_image.replace('_uncal.fits', '_rate.fits')\n",
    "    cal_image  = uncal_image.replace('_uncal.fits', '_cal.fits')\n",
    "    cal_images.append(cal_image)\n",
    "    print(cal_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cal_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_images = glob('images/*_cal.fits')\n",
    "len(cal_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(x) for x in cal_images];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_file = 'MACS0647_%s_image_associations.json' % filt_to_process\n",
    "association_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "association = asn_from_list.asn_from_list(cal_images, rule=DMS_Level3_Base, \n",
    "                                          product_name='MACS0647_'+filt_to_process,\n",
    "                                          asn_rule='Asn_Image')\n",
    "                                          #asn_type='image3')\n",
    "\n",
    "with open(association_file, 'w') as fh:\n",
    "   fh.write(association.dump()[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Defaults:\n",
    "    \"asn_type\": \"None\",\n",
    "    \"asn_rule\": \"DMS_Level3_Base\",\n",
    "        \n",
    "# What we need:\n",
    "    \"asn_type\": \"image3\",\n",
    "    \"asn_rule\": \"Asn_Image\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = int(filt_to_process[1:4])\n",
    "channel = ['sw', 'lw'][lam > 235]    \n",
    "filt_to_process, lam, channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including recommendations from CEERS program DR1 ceers_nircam_reduction.ipynb\n",
    "# 10 minutes for 16 SW images -> 1 image\n",
    "# ## minutes for  4 SW images -> 1 image\n",
    "m = calwebb_image3.Image3Pipeline()\n",
    "m.tweakreg.skip = True  # Turn off TweakRegStep since these simulated images are perfectly aligned (no guide star uncertainties)\n",
    "#m.skymatch.skip = True  # Turn off SkyMatchStep\n",
    "m.outlier_detection.skip = False\n",
    "m.source_catalog.snr_threshold = 5  # 20\n",
    "m.source_catalog.output_file = \"MACS0647_%s_cat.ecsv\" % filt_to_process\n",
    "m.save_results = True  # _id2.fits\n",
    "\n",
    "if channel == 'sw':\n",
    "    m.resample.pixel_scale_ratio = 0.015 / 0.031  # SW images 0.031\" -> 0.015\" / pix\n",
    "elif channel == 'lw':\n",
    "    m.resample.pixel_scale_ratio = 0.03 / 0.063  # LW images 0.063\" -> 0.03\" / pix\n",
    "else:\n",
    "    print('Unknown channel and pixel scale')\n",
    "\n",
    "m.run(association_file)  # run the pipeline with these parameters on these images in association file\n",
    "#m.save_model()  # generate id2.fits in case you didn't above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = 'MACS0647_%s_i2d.fits' % filt_to_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import simple_norm\n",
    "#from scipy.stats import sigmaclip\n",
    "\n",
    "def show(data, percent=99.6):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    norm = simple_norm(data, 'asinh', percent=percent)\n",
    "    plt.imshow(data,norm=norm)\n",
    "    plt.colorbar().set_label('DN$^{-}$/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fits.open(output_image)['SCI'].data\n",
    "print(data.shape)\n",
    "show(data)\n",
    "output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    raw_data = fits.open(uncal_image)['SCI'].data\n",
    "    print(raw_data.shape)\n",
    "    data = 1. * raw_data[0, 3, :, :] - 1. * raw_data[0, 0, :, :]\n",
    "    show(data)\n",
    "    raw_image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If linear images were saved\n",
    "if 0:\n",
    "    linear_image_file = yfile.replace('.yaml', '_linear.fits').replace(output_dir, simulation_dir)\n",
    "    linear_data = fits.open(linear_image_file)['SCI'].data\n",
    "    show(linear_data[0, 3, :, :])\n",
    "    linear_image_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data file is now ready to be run through the [JWST calibration pipeline](https://jwst-pipeline.readthedocs.io/en/stable/) from the beginning. If dark current subtraction is not important for you, you can use Mirage's linear output, skip some of the initial steps of the pipeline, and begin by running the [Jump detection](https://jwst-pipeline.readthedocs.io/en/stable/jwst/jump/index.html?highlight=jump) and [ramp fitting](https://jwst-pipeline.readthedocs.io/en/stable/jwst/ramp_fitting/index.html) steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='mult_sims'></a>\n",
    "## Simulating Multiple Exposures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each yaml file will simulate an exposure for a single pointing using a single detector. To simulate multiple exposures, or a single exposure with multiple detectors, multiple calls to the *imaging_simulator* must be made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Series\n",
    "```python\n",
    "paramlist = [yaml_a1,yaml_a2,yaml_a3,yaml_a4,yaml_a5]\n",
    "\n",
    "def many_sim(paramlist):\n",
    "    '''Function to run many simulations in series\n",
    "    '''\n",
    "    for file in paramlist:\n",
    "        m = imaging_simulator.ImgSim()\n",
    "        m.paramfile = file\n",
    "        m.create()\n",
    "```\n",
    "\n",
    "### In Parallel\n",
    "\n",
    "Since each `yaml` simulations does not depend on the others, we can parallelize the process to speed things up:\n",
    "```python\n",
    "from multiprocessing import Pool\n",
    "\n",
    "n_procs = 5 # number of cores available\n",
    "\n",
    "with Pool(n_procs) as pool:\n",
    "    pool.map(make_sim, paramlist)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://techwiser.com/how-many-cores-does-my-cpu-have/\n",
    "n_procs = 6 # number of cores available"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
